{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "216f962e-5ba1-49c2-8086-6e298fa70d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"\"\"Good morning, everyone!\n",
    "Today, I want to talk about the power of words and how they shape our understanding of the world.\n",
    "Words are everywhere. They are in the books we read, the songs we sing, and the conversations we have. But not all words carry the same weight. Some words, like love, freedom, and change, inspire us. Others, like the, and, and is, simply connect ideas together.\n",
    "In life, we often focus on the big ideas. However, we must not overlook the smaller things that help us communicate. For example, the sun rises in the east. Here, words like the and in might seem unimportant, but they help the sentence make sense.\n",
    "In the field of technology, particularly in natural language processing, we analyze words to understand their meaning. We call common words like the, and, and is stopwords. These words appear so often that they don’t add much meaning to sentences. For instance, if I say, The cat is on the mat, the important words are cat and mat.\n",
    "By removing stopwords, we can focus on the heart of the message. Whether we are working with sentences, paragraphs, or entire books, filtering out stopwords helps us uncover the true meaning hidden in the text.\n",
    "\n",
    "So, as you explore the power of words, remember this: Sometimes, it’s not the words themselves but the ideas behind them that matter most.\n",
    "\n",
    "Thank you!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec41cd0b-a7c8-49bf-801e-3ab1a1f7f728",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning, everyone!\n",
      "Today, I want to talk about the power of words and how they shape our understanding of the world.\n",
      "Words are everywhere. They are in the books we read, the songs we sing, and the conversations we have. But not all words carry the same weight. Some words, like love, freedom, and change, inspire us. Others, like the, and, and is, simply connect ideas together.\n",
      "In life, we often focus on the big ideas. However, we must not overlook the smaller things that help us communicate. For example, the sun rises in the east. Here, words like the and in might seem unimportant, but they help the sentence make sense.\n",
      "In the field of technology, particularly in natural language processing, we analyze words to understand their meaning. We call common words like the, and, and is stopwords. These words appear so often that they don’t add much meaning to sentences. For instance, if I say, The cat is on the mat, the important words are cat and mat.\n",
      "By removing stopwords, we can focus on the heart of the message. Whether we are working with sentences, paragraphs, or entire books, filtering out stopwords helps us uncover the true meaning hidden in the text.\n",
      "\n",
      "So, as you explore the power of words, remember this: Sometimes, it’s not the words themselves but the ideas behind them that matter most.\n",
      "\n",
      "Thank you!\n"
     ]
    }
   ],
   "source": [
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a7fa218-d02b-45d4-962c-044e204ae6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff76f8e3-4b41-493e-b177-3a8cbb5d4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff87d29-f6c1-4ce5-8f6d-95f9221ecaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gauta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e588f93b-287d-4420-bf30-d276d4c96179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1eaffb8-2ffd-4057-8809-1a1342898cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "262113d5-606a-4baa-b970-a03f21edd6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e57d2c29-8f5b-4689-87e2-218a59726f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['Good morning, everyone!', 'Today, I want to talk about the power of words and how they shape our understanding of the world.', 'Words are everywhere.', 'They are in the books we read, the songs we sing, and the conversations we have.', 'But not all words carry the same weight.', 'Some words, like love, freedom, and change, inspire us.', 'Others, like the, and, and is, simply connect ideas together.', 'In life, we often focus on the big ideas.', 'However, we must not overlook the smaller things that help us communicate.', 'For example, the sun rises in the east.', 'Here, words like the and in might seem unimportant, but they help the sentence make sense.', 'In the field of technology, particularly in natural language processing, we analyze words to understand their meaning.', 'We call common words like the, and, and is stopwords.', 'These words appear so often that they don’t add much meaning to sentences.', 'For instance, if I say, The cat is on the mat, the important words are cat and mat.', 'By removing stopwords, we can focus on the heart of the message.', 'Whether we are working with sentences, paragraphs, or entire books, filtering out stopwords helps us uncover the true meaning hidden in the text.', 'So, as you explore the power of words, remember this: Sometimes, it’s not the words themselves but the ideas behind them that matter most.', 'Thank you!']\n"
     ]
    }
   ],
   "source": [
    "#Here  the paragraph is split into list of sentences.\n",
    "sentence=nltk.sent_tokenize(paragraph)\n",
    "print(type(sentence))\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e578713f-256a-4c13-9fc3-6296c676067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply stopwords and filter and then apply stemming\n",
    "\n",
    "for i in range(len(sentence)):\n",
    "    words=nltk.word_tokenize(sentence[i])\n",
    "    words=[stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentence[i]=' '.join(words) # converting all the words into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb249ad1-1845-4471-ad45-aa09020a4719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good morn , everyon !',\n",
       " 'today , i want talk power word shape understand world .',\n",
       " 'word everywher .',\n",
       " 'they book read , song sing , convers .',\n",
       " 'but word carri weight .',\n",
       " 'some word , like love , freedom , chang , inspir us .',\n",
       " 'other , like , , , simpli connect idea togeth .',\n",
       " 'in life , often focu big idea .',\n",
       " 'howev , must overlook smaller thing help us commun .',\n",
       " 'for exampl , sun rise east .',\n",
       " 'here , word like might seem unimport , help sentenc make sens .',\n",
       " 'in field technolog , particularli natur languag process , analyz word understand mean .',\n",
       " 'we call common word like , , stopword .',\n",
       " 'these word appear often ’ add much mean sentenc .',\n",
       " 'for instanc , i say , the cat mat , import word cat mat .',\n",
       " 'by remov stopword , focu heart messag .',\n",
       " 'whether work sentenc , paragraph , entir book , filter stopword help us uncov true mean hidden text .',\n",
       " 'so , explor power word , rememb : sometim , ’ word idea behind matter .',\n",
       " 'thank !']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c050c-d790-48a7-a002-c1f96e8b6d6a",
   "metadata": {},
   "source": [
    "## THIs does not look that good, so lets use another stemmer- Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "987c5cf6-8062-40cb-8fc4-fb49e9ff39a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c1b962a-7e70-4855-9f2f-62684c893646",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85d6264d-f1e6-425e-a89b-cb123be52855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good morning, everyone!',\n",
       " 'Today, I want to talk about the power of words and how they shape our understanding of the world.',\n",
       " 'Words are everywhere.',\n",
       " 'They are in the books we read, the songs we sing, and the conversations we have.',\n",
       " 'But not all words carry the same weight.',\n",
       " 'Some words, like love, freedom, and change, inspire us.',\n",
       " 'Others, like the, and, and is, simply connect ideas together.',\n",
       " 'In life, we often focus on the big ideas.',\n",
       " 'However, we must not overlook the smaller things that help us communicate.',\n",
       " 'For example, the sun rises in the east.',\n",
       " 'Here, words like the and in might seem unimportant, but they help the sentence make sense.',\n",
       " 'In the field of technology, particularly in natural language processing, we analyze words to understand their meaning.',\n",
       " 'We call common words like the, and, and is stopwords.',\n",
       " 'These words appear so often that they don’t add much meaning to sentences.',\n",
       " 'For instance, if I say, The cat is on the mat, the important words are cat and mat.',\n",
       " 'By removing stopwords, we can focus on the heart of the message.',\n",
       " 'Whether we are working with sentences, paragraphs, or entire books, filtering out stopwords helps us uncover the true meaning hidden in the text.',\n",
       " 'So, as you explore the power of words, remember this: Sometimes, it’s not the words themselves but the ideas behind them that matter most.',\n",
       " 'Thank you!']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting all the proper sentences from the paragraph\n",
    "sentence=nltk.sent_tokenize(paragraph)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a85cf046-7c11-4b17-a16d-28b0168131c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply stopwords and filter and then apply snowball stemming\n",
    "\n",
    "for i in range(len(sentence)):\n",
    "    words=nltk.word_tokenize(sentence[i])\n",
    "    words=[snowball.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentence[i]=' '.join(words) # converting all the words into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f47f764b-5079-4bca-b37b-5edad3090dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good morn , everyon !',\n",
       " 'today , i want talk power word shape understand world .',\n",
       " 'word everywher .',\n",
       " 'they book read , song sing , convers .',\n",
       " 'but word carri weight .',\n",
       " 'some word , like love , freedom , chang , inspir us .',\n",
       " 'other , like , , , simpli connect idea togeth .',\n",
       " 'in life , often focus big idea .',\n",
       " 'howev , must overlook smaller thing help us communic .',\n",
       " 'for exampl , sun rise east .',\n",
       " 'here , word like might seem unimport , help sentenc make sens .',\n",
       " 'in field technolog , particular natur languag process , analyz word understand mean .',\n",
       " 'we call common word like , , stopword .',\n",
       " 'these word appear often ’ add much mean sentenc .',\n",
       " 'for instanc , i say , the cat mat , import word cat mat .',\n",
       " 'by remov stopword , focus heart messag .',\n",
       " 'whether work sentenc , paragraph , entir book , filter stopword help us uncov true mean hidden text .',\n",
       " 'so , explor power word , rememb : sometim , ’ word idea behind matter .',\n",
       " 'thank !']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de9762a-3f7c-4b6d-9d22-b793a24c5a24",
   "metadata": {},
   "source": [
    "## this still doesnt look good, So lets use lemmatization tecchniquee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6d1d77c-ffae-467d-a7f2-d07883eaba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a7b3b30-e623-4d2a-a629-32d17f31320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f79436bf-3fcd-4ae0-97b3-44acdb0c34ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good morning, everyone!',\n",
       " 'Today, I want to talk about the power of words and how they shape our understanding of the world.',\n",
       " 'Words are everywhere.',\n",
       " 'They are in the books we read, the songs we sing, and the conversations we have.',\n",
       " 'But not all words carry the same weight.',\n",
       " 'Some words, like love, freedom, and change, inspire us.',\n",
       " 'Others, like the, and, and is, simply connect ideas together.',\n",
       " 'In life, we often focus on the big ideas.',\n",
       " 'However, we must not overlook the smaller things that help us communicate.',\n",
       " 'For example, the sun rises in the east.',\n",
       " 'Here, words like the and in might seem unimportant, but they help the sentence make sense.',\n",
       " 'In the field of technology, particularly in natural language processing, we analyze words to understand their meaning.',\n",
       " 'We call common words like the, and, and is stopwords.',\n",
       " 'These words appear so often that they don’t add much meaning to sentences.',\n",
       " 'For instance, if I say, The cat is on the mat, the important words are cat and mat.',\n",
       " 'By removing stopwords, we can focus on the heart of the message.',\n",
       " 'Whether we are working with sentences, paragraphs, or entire books, filtering out stopwords helps us uncover the true meaning hidden in the text.',\n",
       " 'So, as you explore the power of words, remember this: Sometimes, it’s not the words themselves but the ideas behind them that matter most.',\n",
       " 'Thank you!']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting all the proper sentences from the paragraph\n",
    "sentence=nltk.sent_tokenize(paragraph)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d4a41b8-4cdf-46ec-b499-77b627a430e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply stopwords and filter and then apply lemmatization\n",
    "\n",
    "for i in range(len(sentence)):\n",
    "    words=nltk.word_tokenize(sentence[i])\n",
    "    words=[lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))] ## Here we can give pos tag in lemmatize\n",
    "    sentence[i]=' '.join(words) # converting all the words into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9bce4f56-5d17-48d8-996f-8b3786f519c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good morning , everyone !',\n",
       " 'Today , I want talk power word shape understanding world .',\n",
       " 'Words everywhere .',\n",
       " 'They book read , song sing , conversation .',\n",
       " 'But word carry weight .',\n",
       " 'Some word , like love , freedom , change , inspire u .',\n",
       " 'Others , like , , , simply connect idea together .',\n",
       " 'In life , often focus big idea .',\n",
       " 'However , must overlook smaller thing help u communicate .',\n",
       " 'For example , sun rise east .',\n",
       " 'Here , word like might seem unimportant , help sentence make sense .',\n",
       " 'In field technology , particularly natural language processing , analyze word understand meaning .',\n",
       " 'We call common word like , , stopwords .',\n",
       " 'These word appear often ’ add much meaning sentence .',\n",
       " 'For instance , I say , The cat mat , important word cat mat .',\n",
       " 'By removing stopwords , focus heart message .',\n",
       " 'Whether working sentence , paragraph , entire book , filtering stopwords help u uncover true meaning hidden text .',\n",
       " 'So , explore power word , remember : Sometimes , ’ word idea behind matter .',\n",
       " 'Thank !']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence ## here we can see that cases are not at all changed, if we want all in same case, then we can use lower() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae95b44-f7e0-4666-9ce6-ebcbed8a8f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
